{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DFIN6Hzm0gW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from Models import SAE, CNN_AE, LSTM_AE, GRU_AE, Bi_LSTM_AE, CNN_Bi_LSTM_AE, Causal_CNN_AE, Wavenet, Attention_Bi_LSTM_AE, Attention_CNN_Bi_LSTM_AE, Attention_Wavenet\n",
    "\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhDMeVP4m3YW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utKnpapAnwDS"
   },
   "outputs": [],
   "source": [
    "svm_reg = SVR(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gag8LETrRK5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "dataset_path = './datasets/regression/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmnxYv1z0kbj"
   },
   "outputs": [],
   "source": [
    "def n_steps_reshape(X_train_full, y_train_full, n_steps=10, for_rnn=False):\n",
    "    new_data = []\n",
    "    new_label = []\n",
    "    columns = X_train_full.columns\n",
    "    for i in range(X_train_full.shape[0]-n_steps):\n",
    "        new_instance = []\n",
    "        train_data = X_train_full[i:i+n_steps]\n",
    "        for c in columns:\n",
    "            for v in train_data[c].values:\n",
    "                new_instance.append(v)\n",
    "#         for _, row in train_data.iterrows():\n",
    "#             for c in columns:\n",
    "#                 new_instance.append(row[c])\n",
    "        new_label.append(y_train_full[i+n_steps])\n",
    "        new_data.append(new_instance)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    new_data = scaler.fit_transform(new_data)\n",
    "    new_label = scaler.fit_transform(np.array(new_label).reshape(-1,1))\n",
    "\n",
    "    if for_rnn:\n",
    "        return np.array(new_data).reshape(len(new_data), n_steps, columns.shape[0]), new_label\n",
    "    else:\n",
    "        return np.array(new_data), new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXJeGu4eguz"
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(n_steps, n_features):\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.LSTM(128, return_sequences=True, input_shape=[n_steps, n_features]),\n",
    "        keras.layers.LSTM(128),\n",
    "        keras.layers.Dense(1, activation=keras.layers.LeakyReLU(alpha=0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWwo0QuiVIXA"
   },
   "outputs": [],
   "source": [
    "from TRepNet import TRepNet\n",
    "\n",
    "def get_codings(X_train, n_steps, n_features):\n",
    "#     X_train, X_test, n_steps = flatten_ts(train_x, test_x)\n",
    "#     X_train, X_test = rnn_reshape(X_train, X_test, n_steps // n_features, n_features)\n",
    "    encoder, decoder = TRepNet(n_steps, n_features, activation='elu')\n",
    "    model = keras.models.Sequential([encoder, decoder])\n",
    "    \n",
    "    model.compile(loss=\"mae\", optimizer=keras.optimizers.Nadam(lr=0.001, clipnorm=1.), metrics=['mae'])\n",
    "    history = model.fit(X_train, X_train, epochs=500, batch_size=16, validation_split=0.20, callbacks=[es], verbose=1, shuffle=False)\n",
    "\n",
    "    # Codings\n",
    "    return encoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUFfShohzVLW"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for fn in [SAE, CNN_AE, LSTM_AE, GRU_AE, Bi_LSTM_AE, CNN_Bi_LSTM_AE, Causal_CNN_AE, Wavenet, TRepNet]:\n",
    "#     results = []\n",
    "\n",
    "#     print(fn.__name__)\n",
    "    \n",
    "#     name = 'Solar Generation'\n",
    "#     solar_data = pd.read_csv(dataset_path + 'Solar/data.csv', quotechar='\"').fillna(0)\n",
    "#     solar_data_X = solar_data.drop(columns=['SITE_NO', 'DATE', 'TIME'])\n",
    "#     solar_data_y = solar_data['GEN_ENERGY']\n",
    "#     X_train_full, y_train_full = n_steps_reshape(solar_data_X, solar_data_y, 10, for_rnn=True)\n",
    "#     X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "#     svm_reg.fit(X_train, y_train)\n",
    "#     pred = svm_reg.predict(X_test)\n",
    "#     print(mse(y_test, pred))\n",
    "#     results.append({'dataset': name, 'MSE': mse(y_test, pred)})\n",
    "    \n",
    "#     name = 'Beijing PM 2.5'\n",
    "#     beijing_data = pd.read_csv(dataset_path + 'Beijing-PM25.csv').dropna().drop(columns=['No', 'year']).reset_index(drop=True)\n",
    "#     beijing_data_X = pd.get_dummies(beijing_data, columns=['cbwd'])\n",
    "#     beijing_data_y = beijing_data['pm2.5']\n",
    "#     X_train_full, y_train_full = n_steps_reshape(beijing_data_X, beijing_data_y, 10, for_rnn=True)\n",
    "#     X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "#     svm_reg.fit(X_train, y_train)\n",
    "#     pred = svm_reg.predict(X_test)\n",
    "#     print(mse(y_test, pred))\n",
    "#     results.append({'dataset': name, 'MSE': mse(y_test, pred)})\n",
    "    \n",
    "#     name = 'Appliance Energy Prediction'\n",
    "#     energy_data = pd.read_csv(dataset_path + 'energydata_complete.csv')\n",
    "#     enery_data_X = energy_data.drop(columns=['date'])\n",
    "#     enery_data_y = energy_data['Appliances']\n",
    "#     X_train_full, y_train_full = n_steps_reshape(enery_data_X, enery_data_y, 10, for_rnn=True)\n",
    "#     X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "#     svm_reg.fit(X_train, y_train)\n",
    "#     pred = svm_reg.predict(X_test)\n",
    "#     print(mse(y_test, pred))\n",
    "#     results.append({'dataset': name, 'MSE': mse(y_test, pred)})\n",
    "    \n",
    "#     name = 'Parking Birmingham'\n",
    "#     parking_data = pd.read_csv(dataset_path + 'Parking Birmingham.csv')\n",
    "#     parking_data_X = parking_data.drop(columns=['SystemCodeNumber', 'LastUpdated'])\n",
    "#     parking_data_y = parking_data['Occupancy']\n",
    "#     X_train_full, y_train_full = n_steps_reshape(parking_data_X, parking_data_y, 10, for_rnn=True)\n",
    "#     X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "#     svm_reg.fit(X_train, y_train)\n",
    "#     pred = svm_reg.predict(X_test)\n",
    "#     print(mse(y_test, pred))\n",
    "#     results.append({'dataset': name, 'MSE': mse(y_test, pred)})\n",
    "    \n",
    "#     name = 'Daily Deemand Forecasting'\n",
    "#     demand_data = pd.read_csv(dataset_path + 'Daily_Demand_Forecasting_Orders.csv', sep=';')\n",
    "#     demand_data_X = demand_data\n",
    "#     demand_data_y = demand_data['Target']\n",
    "#     X_train_full, y_train_full = n_steps_reshape(demand_data_X, demand_data_y, 10, for_rnn=True)\n",
    "#     X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "#     svm_reg.fit(X_train, y_train)\n",
    "#     pred = svm_reg.predict(X_test)\n",
    "#     print(mse(y_test, pred))\n",
    "#     results.append({'dataset': name, 'MSE': mse(y_test, pred)})\n",
    "    \n",
    "#     pd.DataFrame(results).to_csv('./results/regression-'+ fn.__name__ +'-results.csv', index=False)\n",
    "# print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPp3VfMma3MQ"
   },
   "source": [
    "### Solar Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021132202063766075\n"
     ]
    }
   ],
   "source": [
    "solar_data = pd.read_csv(dataset_path + 'Solar/data.csv', quotechar='\"').fillna(0)\n",
    "solar_data_X = solar_data.drop(columns=['SITE_NO', 'DATE', 'TIME'])\n",
    "solar_data_y = solar_data['GEN_ENERGY']\n",
    "X_train_full, y_train_full = n_steps_reshape(solar_data_X, solar_data_y, 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred = svm_reg.predict(X_test)\n",
    "print(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V23x1xM6jEbj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(X_train.shape[0], 10, solar_data_X.shape[1]), X_test.reshape(X_test.shape[0], 10, solar_data_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "glLvq1TVfPFW",
    "outputId": "f49cbdd8-e98d-4987-e419-c9d0069cf412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39514 samples, validate on 4391 samples\n",
      "Epoch 1/10\n",
      "39514/39514 [==============================] - 23s 588us/sample - loss: 0.1823 - mse: 0.1823 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 2/10\n",
      "39514/39514 [==============================] - 14s 350us/sample - loss: 0.1681 - mse: 0.1681 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3/10\n",
      "39514/39514 [==============================] - 13s 323us/sample - loss: 0.1595 - mse: 0.1595 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 4/10\n",
      "39514/39514 [==============================] - 13s 331us/sample - loss: 0.1549 - mse: 0.1549 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 5/10\n",
      "39514/39514 [==============================] - 12s 306us/sample - loss: 0.1535 - mse: 0.1535 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6/10\n",
      "39514/39514 [==============================] - 13s 319us/sample - loss: 0.1538 - mse: 0.1538 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 7/10\n",
      "39514/39514 [==============================] - 12s 297us/sample - loss: 0.1511 - mse: 0.1511 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8/10\n",
      "39514/39514 [==============================] - 12s 313us/sample - loss: 0.1528 - mse: 0.1528 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9/10\n",
      "39514/39514 [==============================] - 13s 328us/sample - loss: 0.1491 - mse: 0.1491 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10/10\n",
      "39514/39514 [==============================] - 13s 319us/sample - loss: 0.1466 - mse: 0.1466 - val_loss: 0.0144 - val_mse: 0.0144\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model(X_train.shape[1], X_train.shape[2])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mlhNIys2kjen",
    "outputId": "4b25b7c6-9c3a-4c92-a0a4-271281965425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021210585206084046"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yoT_YvZbD2z"
   },
   "source": [
    "### Beijing PM 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04616497588589663\n"
     ]
    }
   ],
   "source": [
    "beijing_data = pd.read_csv(dataset_path + 'Beijing-PM25.csv').dropna().drop(columns=['No', 'year']).reset_index(drop=True)\n",
    "beijing_data_X = pd.get_dummies(beijing_data, columns=['cbwd'])\n",
    "beijing_data_y = beijing_data['pm2.5']\n",
    "X_train_full, y_train_full = n_steps_reshape(beijing_data_X, beijing_data_y, 10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred = svm_reg.predict(X_test)\n",
    "print(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7kNG5QAo6ZV"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.reshape(X_train.shape[0], 10, beijing_data_X.shape[1]), X_test.reshape(X_test.shape[0], 10, beijing_data_X.shape[1]), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "RO164XQUo6vZ",
    "outputId": "e7dcd817-638f-4a5f-aad1-ecd4d375afcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30057 samples, validate on 3340 samples\n",
      "Epoch 1/10\n",
      "30057/30057 [==============================] - 14s 481us/sample - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 2/10\n",
      "30057/30057 [==============================] - 8s 264us/sample - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 3/10\n",
      "30057/30057 [==============================] - 8s 259us/sample - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 4/10\n",
      "30057/30057 [==============================] - 8s 263us/sample - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 5/10\n",
      "30057/30057 [==============================] - 8s 257us/sample - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 6/10\n",
      "30057/30057 [==============================] - 8s 259us/sample - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 7/10\n",
      "30057/30057 [==============================] - 8s 263us/sample - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 8/10\n",
      "30057/30057 [==============================] - 8s 262us/sample - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 9/10\n",
      "30057/30057 [==============================] - 8s 260us/sample - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 10/10\n",
      "30057/30057 [==============================] - 8s 262us/sample - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0491 - val_mse: 0.0491\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model(X_train.shape[1], X_train.shape[2])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8akS68rTo_jh",
    "outputId": "1eebd0cf-8279-453b-cdfd-43087266f1db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052009185489119016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4kTlxKjpF0i"
   },
   "source": [
    "### Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15780 samples, validate on 3945 samples\n",
      "Epoch 1/500\n",
      "15780/15780 [==============================] - 258s 16ms/sample - loss: 0.4215 - mae: 0.4215 - val_loss: 0.8134 - val_mae: 0.8134\n",
      "Epoch 2/500\n",
      "15780/15780 [==============================] - 198s 13ms/sample - loss: 0.3698 - mae: 0.3698 - val_loss: 0.8269 - val_mae: 0.8269\n",
      "Epoch 3/500\n",
      "15780/15780 [==============================] - 198s 13ms/sample - loss: 0.3537 - mae: 0.3537 - val_loss: 0.7886 - val_mae: 0.7886\n",
      "Epoch 4/500\n",
      "15780/15780 [==============================] - 208s 13ms/sample - loss: 0.3432 - mae: 0.3432 - val_loss: 0.7836 - val_mae: 0.7836\n",
      "Epoch 5/500\n",
      "15780/15780 [==============================] - 212s 13ms/sample - loss: 0.3356 - mae: 0.3356 - val_loss: 0.8037 - val_mae: 0.8037\n",
      "Epoch 6/500\n",
      "15780/15780 [==============================] - 198s 13ms/sample - loss: 0.3319 - mae: 0.3319 - val_loss: 0.7722 - val_mae: 0.7722\n",
      "Epoch 7/500\n",
      "15780/15780 [==============================] - 196s 12ms/sample - loss: 0.3266 - mae: 0.3266 - val_loss: 0.7833 - val_mae: 0.7833\n",
      "Epoch 8/500\n",
      "15780/15780 [==============================] - 204s 13ms/sample - loss: 0.3267 - mae: 0.3267 - val_loss: 0.8209 - val_mae: 0.8209\n",
      "Epoch 9/500\n",
      "15780/15780 [==============================] - 203s 13ms/sample - loss: 0.3204 - mae: 0.3204 - val_loss: 0.7595 - val_mae: 0.7595\n",
      "Epoch 10/500\n",
      "15780/15780 [==============================] - 205s 13ms/sample - loss: 0.3170 - mae: 0.3170 - val_loss: 0.7464 - val_mae: 0.7464\n",
      "Epoch 11/500\n",
      "15780/15780 [==============================] - 209s 13ms/sample - loss: 0.3166 - mae: 0.3166 - val_loss: 0.7563 - val_mae: 0.7563\n",
      "Epoch 12/500\n",
      "15780/15780 [==============================] - 204s 13ms/sample - loss: 0.3121 - mae: 0.3121 - val_loss: 0.7087 - val_mae: 0.7087\n",
      "Epoch 13/500\n",
      "15780/15780 [==============================] - 203s 13ms/sample - loss: 0.3106 - mae: 0.3106 - val_loss: 0.7422 - val_mae: 0.7422\n",
      "Epoch 14/500\n",
      "15780/15780 [==============================] - 203s 13ms/sample - loss: 0.3064 - mae: 0.3064 - val_loss: 0.6955 - val_mae: 0.6955\n",
      "Epoch 15/500\n",
      "15780/15780 [==============================] - 205s 13ms/sample - loss: 0.3015 - mae: 0.3015 - val_loss: 0.6649 - val_mae: 0.6649\n",
      "Epoch 16/500\n",
      "15780/15780 [==============================] - 205s 13ms/sample - loss: 0.3009 - mae: 0.3009 - val_loss: 0.6845 - val_mae: 0.6845\n",
      "Epoch 17/500\n",
      "15780/15780 [==============================] - 200s 13ms/sample - loss: 0.2939 - mae: 0.2939 - val_loss: 0.6214 - val_mae: 0.6214\n",
      "Epoch 18/500\n",
      "15780/15780 [==============================] - 204s 13ms/sample - loss: 0.2940 - mae: 0.2940 - val_loss: 0.6114 - val_mae: 0.6114\n",
      "Epoch 19/500\n",
      "15780/15780 [==============================] - 206s 13ms/sample - loss: 0.2920 - mae: 0.2920 - val_loss: 0.6060 - val_mae: 0.6060\n",
      "Epoch 20/500\n",
      "15780/15780 [==============================] - 212s 13ms/sample - loss: 0.2898 - mae: 0.2898 - val_loss: 0.6412 - val_mae: 0.6412\n",
      "Epoch 21/500\n",
      "15780/15780 [==============================] - 207s 13ms/sample - loss: 0.2892 - mae: 0.2892 - val_loss: 0.6324 - val_mae: 0.6324\n",
      "Epoch 22/500\n",
      "15780/15780 [==============================] - 202s 13ms/sample - loss: 0.2841 - mae: 0.2841 - val_loss: 0.6134 - val_mae: 0.6134\n",
      "Epoch 23/500\n",
      "15780/15780 [==============================] - 204s 13ms/sample - loss: 0.2827 - mae: 0.2827 - val_loss: 0.6404 - val_mae: 0.6404\n",
      "Epoch 24/500\n",
      "15780/15780 [==============================] - 208s 13ms/sample - loss: 0.2797 - mae: 0.2797 - val_loss: 0.6306 - val_mae: 0.6306\n",
      "3.263552092699289\n"
     ]
    }
   ],
   "source": [
    "energy_data = pd.read_csv(dataset_path + 'energydata_complete.csv')\n",
    "enery_data_X = energy_data.drop(columns=['date'])\n",
    "enery_data_y = energy_data['Appliances']\n",
    "X_train_full, y_train_full = n_steps_reshape(enery_data_X, enery_data_y, 10, for_rnn=True)\n",
    "X_train_full = get_codings(X_train_full, 10, X_train_full.shape[2])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred = svm_reg.predict(X_test)\n",
    "print(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZGDyuFapF0u"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.reshape(X_train.shape[0], 10, enery_data_X.shape[1]), X_test.reshape(X_test.shape[0], 10, enery_data_X.shape[1]), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "9k7xwM-zpF0x",
    "outputId": "51591ea9-3743-4691-c564-fe156e0e5f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14202 samples, validate on 1578 samples\n",
      "Epoch 1/10\n",
      "14202/14202 [==============================] - 11s 754us/sample - loss: 2.3596 - mse: 2.3596 - val_loss: 2.2066 - val_mse: 2.2066\n",
      "Epoch 2/10\n",
      "14202/14202 [==============================] - 4s 302us/sample - loss: 1.9699 - mse: 1.9699 - val_loss: 2.1274 - val_mse: 2.1274\n",
      "Epoch 3/10\n",
      "14202/14202 [==============================] - 4s 285us/sample - loss: 1.8586 - mse: 1.8586 - val_loss: 2.1824 - val_mse: 2.1824\n",
      "Epoch 4/10\n",
      "14202/14202 [==============================] - 4s 284us/sample - loss: 1.7828 - mse: 1.7828 - val_loss: 2.1673 - val_mse: 2.1673\n",
      "Epoch 5/10\n",
      "14202/14202 [==============================] - 4s 291us/sample - loss: 1.7056 - mse: 1.7056 - val_loss: 2.0879 - val_mse: 2.0879\n",
      "Epoch 6/10\n",
      "14202/14202 [==============================] - 4s 280us/sample - loss: 1.6557 - mse: 1.6557 - val_loss: 2.0062 - val_mse: 2.0062\n",
      "Epoch 7/10\n",
      "14202/14202 [==============================] - 4s 288us/sample - loss: 1.6291 - mse: 1.6291 - val_loss: 1.9741 - val_mse: 1.9741\n",
      "Epoch 8/10\n",
      "14202/14202 [==============================] - 4s 279us/sample - loss: 1.5202 - mse: 1.5202 - val_loss: 2.0345 - val_mse: 2.0345\n",
      "Epoch 9/10\n",
      "14202/14202 [==============================] - 4s 310us/sample - loss: 1.4698 - mse: 1.4698 - val_loss: 2.1634 - val_mse: 2.1634\n",
      "Epoch 10/10\n",
      "14202/14202 [==============================] - 4s 294us/sample - loss: 1.4631 - mse: 1.4631 - val_loss: 2.1316 - val_mse: 2.1316\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model(X_train.shape[1], X_train.shape[2])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "L50Rj5fxpF0y",
    "outputId": "7378cba7-cdae-4cb2-896f-0378431d6231"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.980028086438499"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sasoJRUc2NEe"
   },
   "source": [
    "### Parking Birmingham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0347304968433626\n"
     ]
    }
   ],
   "source": [
    "parking_data = pd.read_csv(dataset_path + 'Parking Birmingham.csv')\n",
    "parking_data_X = parking_data.drop(columns=['SystemCodeNumber', 'LastUpdated'])\n",
    "parking_data_y = parking_data['Occupancy']\n",
    "X_train_full, y_train_full = n_steps_reshape(parking_data_X, parking_data_y, 10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred = svm_reg.predict(X_test)\n",
    "print(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38n1kCP42NEs"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.reshape(X_train.shape[0], 10, parking_data_X.shape[1]), X_test.reshape(X_test.shape[0], 10, parking_data_X.shape[1]), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "weNruGOX2NEt",
    "outputId": "05f179b1-1ef0-477c-da08-707bab62b72b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25708 samples, validate on 2857 samples\n",
      "Epoch 1/10\n",
      "25708/25708 [==============================] - 14s 531us/sample - loss: 0.1127 - mse: 0.1127 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 2/10\n",
      "25708/25708 [==============================] - 7s 285us/sample - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 3/10\n",
      "25708/25708 [==============================] - 7s 286us/sample - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 4/10\n",
      "25708/25708 [==============================] - 7s 282us/sample - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 5/10\n",
      "25708/25708 [==============================] - 7s 274us/sample - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 6/10\n",
      "25708/25708 [==============================] - 7s 279us/sample - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 7/10\n",
      "25708/25708 [==============================] - 7s 276us/sample - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 8/10\n",
      "25708/25708 [==============================] - 7s 271us/sample - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 9/10\n",
      "25708/25708 [==============================] - 7s 280us/sample - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 10/10\n",
      "25708/25708 [==============================] - 7s 274us/sample - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0324 - val_mse: 0.0324\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model(X_train.shape[1], X_train.shape[2])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DpWQRbi32NEv",
    "outputId": "7656a894-2c7b-4cae-ae97-8bfd6880cae4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027566600022463545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Or0gSJ_C8Va7"
   },
   "source": [
    "### Daily Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4818427980593791\n"
     ]
    }
   ],
   "source": [
    "demand_data = pd.read_csv(dataset_path + 'Daily_Demand_Forecasting_Orders.csv', sep=';')\n",
    "demand_data_X = demand_data\n",
    "demand_data_y = demand_data['Target']\n",
    "X_train_full, y_train_full = n_steps_reshape(demand_data_X, demand_data_y, 10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=7)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred = svm_reg.predict(X_test)\n",
    "print(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bvfylva18VbI"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.reshape(X_train.shape[0], 10, demand_data_X.shape[1]), X_test.reshape(X_test.shape[0], 10, demand_data_X.shape[1]), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "AAFLb4Oi8VbJ",
    "outputId": "4f318ac9-0956-4f26-ecf2-eb4af4e14efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36 samples, validate on 4 samples\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 7s 202ms/sample - loss: 0.6588 - mse: 0.6588 - val_loss: 0.2509 - val_mse: 0.2509\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 2ms/sample - loss: 0.5866 - mse: 0.5866 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 2ms/sample - loss: 0.5192 - mse: 0.5192 - val_loss: 0.3176 - val_mse: 0.3176\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 2ms/sample - loss: 0.4640 - mse: 0.4640 - val_loss: 0.3429 - val_mse: 0.3429\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 2ms/sample - loss: 0.4172 - mse: 0.4172 - val_loss: 0.3804 - val_mse: 0.3804\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 2ms/sample - loss: 0.3776 - mse: 0.3776 - val_loss: 0.4345 - val_mse: 0.4345\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model(X_train.shape[1], X_train.shape[2])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "kuyTk92i8VbL",
    "outputId": "b3e3e8fc-e078-4902-b00b-bdd3ab63ba62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7599617685253022"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
