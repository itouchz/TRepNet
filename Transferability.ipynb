{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer, StandardScaler\n",
    "from datasets import load_data, random_benchmark, list_datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from Imputation import remove_and_impute\n",
    "from Models import SAE, CNN_AE, LSTM_AE, GRU_AE, Bi_LSTM_AE, CNN_Bi_LSTM_AE, Causal_CNN_AE, Wavenet\n",
    "\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Virtual devices must be set before GPUs have been initialized\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = './results/others/'\n",
    "inception = pd.read_csv(result_path + 'InceptionTime-128.csv')[['dataset_name', 'accuracy']]\n",
    "resnet_ucr = pd.read_csv(result_path + 'resnet-ucr.csv')[['dataset_name', 'accuracy']]\n",
    "resnet_uea = pd.read_csv(result_path + 'resnet-uea.csv')[['dataset_name', 'accuracy']]\n",
    "resnet_mts = pd.read_csv(result_path + 'resnet-mts.csv')[['dataset_name', 'accuracy']]\n",
    "hive_cote = pd.read_csv(result_path + 'singleTrainTest.csv')[['dataset_name', 'HIVE-COTE']]\n",
    "dtw_uea = pd.read_csv(result_path + 'usrl_uea.csv')[['dataset_name', 'DTW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_dim(original_dim):\n",
    "    if original_dim // 1.3 >= 512:\n",
    "        return 512\n",
    "    elif original_dim // 1.3 <= 128:\n",
    "        return 128\n",
    "    else:\n",
    "        return int(original_dim // 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def flatten_ts(train, test):\n",
    "    new_train, new_test = [], []\n",
    "    train_lens = []\n",
    "    \n",
    "    for _, row in train.iterrows():\n",
    "        for i in row.index:\n",
    "            train_lens.append(len(row[i]))\n",
    "\n",
    "    maxlen = np.ceil(np.average(train_lens)).astype(int)\n",
    "    \n",
    "    for _, row in train.iterrows():\n",
    "        new_list = []\n",
    "        for i in row.index:\n",
    "            ts = []\n",
    "            for j in range(len(row[i])):\n",
    "                ts.append(row[i][j])\n",
    "            new_list.append(ts)\n",
    "        new_train.append(pad_sequences(new_list, maxlen=maxlen, dtype='float32'))\n",
    "        \n",
    "    for _, row in test.iterrows():\n",
    "        new_list = []\n",
    "        for i in row.index:\n",
    "            ts = []\n",
    "            for j in range(len(row[i])):\n",
    "                ts.append(row[i][j])\n",
    "            new_list.append(ts)\n",
    "        new_test.append(pad_sequences(new_list, maxlen=maxlen, dtype='float32'))\n",
    "            \n",
    "    train_df = pd.DataFrame(np.array(new_train).reshape(train.shape[0], maxlen * train.columns.shape[0]))\n",
    "    test_df = pd.DataFrame(np.array(new_test).reshape(test.shape[0], maxlen * train.columns.shape[0]))\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(train_df)\n",
    "    return scaler.transform(train_df), scaler.transform(test_df), maxlen * train.columns.shape[0]\n",
    "#     return np.array(train_df), np.array(test_df), maxlen * train.columns.shape[0]\n",
    "\n",
    "def rnn_reshape(train, test, n_steps, n_features):\n",
    "#     train, test = flatten_ts(train, test)\n",
    "    return train.reshape(train.shape[0], n_steps, n_features), test.reshape(test.shape[0], n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "# mc = keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TRepNet import TRepNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM >> {'accuracy': 0.8810606060606061, 'f1': 0.8810904426573477}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_x, train_y, test_x, test_y = load_data('FordA', univariate=True)    \n",
    "\n",
    "n_features = train_x.columns.shape[0]\n",
    "\n",
    "X_train, X_test, n_steps = flatten_ts(train_x, test_x)\n",
    "X_train, X_test = rnn_reshape(X_train, X_test, n_steps // n_features, n_features)\n",
    "\n",
    "encoder, decoder = TRepNet(n_steps // n_features, n_features, activation='elu')\n",
    "model = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "model.compile(loss=\"mae\", optimizer=keras.optimizers.Nadam(lr=0.001, clipnorm=1.), metrics=['mae'])\n",
    "history = model.fit(X_train, X_train, epochs=500, batch_size=16, validation_data=[X_test, X_test], callbacks=[es], verbose=0, shuffle=False)\n",
    "\n",
    "# Codings\n",
    "codings_train = encoder.predict(X_train)\n",
    "codings_test = encoder.predict(X_test)\n",
    "\n",
    "# SVM\n",
    "svm_clf = SVC(random_state=7, gamma='scale')\n",
    "nb_classes = np.unique(train_y).shape[0]\n",
    "train_size = codings_train.shape[0]\n",
    "if train_size // nb_classes < 5 or train_size < 50:\n",
    "    svm_clf.fit(codings_train, train_y)\n",
    "else:\n",
    "    grid_search = GridSearchCV(svm_clf, {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, np.inf]}, cv=5, iid=False, n_jobs=-1)\n",
    "    if train_size <= 10000:\n",
    "        grid_search.fit(codings_train, train_y)\n",
    "    else:\n",
    "        codings_train, _, train_y, _  = train_test_split(codings_train, train_y, train_size=10000, random_state=7, stratify=train_y)\n",
    "        grid_search.fit(codings_train, train_y)       \n",
    "    svm_clf = grid_search.best_estimator_\n",
    "\n",
    "    svm_clf.fit(codings_train, train_y)\n",
    "\n",
    "pred = svm_clf.predict(codings_test)\n",
    "svm_scores = {'accuracy': accuracy_score(test_y, pred), 'f1': f1_score(test_y, pred, average='weighted')}\n",
    "print('SVM >>', svm_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when tuning start with learning rate->mini_batch_size -> \n",
    "# momentum-> #hidden_units -> # learning_rate_decay -> #layers \n",
    "\n",
    "def evaluate(data_name, univariate):\n",
    "    print('Data: ', data_name)\n",
    "    train_x, train_y, test_x, test_y = load_data(data_name, univariate=univariate)    \n",
    "    n_features = train_x.columns.shape[0]\n",
    "        \n",
    "    X_train, X_test, n_steps = flatten_ts(train_x, test_x)\n",
    "    X_train, X_test = rnn_reshape(X_train, X_test, n_steps // n_features, n_features)\n",
    "            \n",
    "    encoder, decoder = TRepNet(n_steps // n_features, n_features, activation='elu')\n",
    "    model = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "    model.compile(loss=\"mae\", optimizer=keras.optimizers.Nadam(lr=0.001, clipnorm=1.), metrics=['mae'])\n",
    "    history = model.fit(X_train, X_train, epochs=500, batch_size=16, validation_data=[X_test, X_test], callbacks=[es], verbose=0, shuffle=False)\n",
    "    \n",
    "    # Codings\n",
    "    codings_train = encoder.predict(X_train)\n",
    "    codings_test = encoder.predict(X_test)\n",
    "\n",
    "    # SVM\n",
    "    pred = svm_clf.predict(codings_test)\n",
    "    svm_scores = {'accuracy': accuracy_score(test_y, pred), 'f1': f1_score(test_y, pred, average='weighted')}\n",
    "    print('SVM >>', svm_scores)\n",
    "\n",
    "\n",
    "    # SOTA Results\n",
    "    print('*'*10)\n",
    "    print('InceptionTime:', inception[inception['dataset_name'] == data_name]['accuracy'].values[0] if len(inception[inception['dataset_name'] == data_name]['accuracy'].values) >= 1 else 'N/A')\n",
    "    print('ResNet:', resnet_ucr[resnet_ucr['dataset_name'] == data_name]['accuracy'].values[0] if len(resnet_ucr[resnet_ucr['dataset_name'] == data_name]['accuracy'].values) >= 1 else 'N/A')\n",
    "    print('ResNet:', resnet_uea[resnet_uea['dataset_name'] == data_name]['accuracy'].values[0] if len(resnet_uea[resnet_uea['dataset_name'] == data_name]['accuracy'].values) >= 1 else 'N/A')\n",
    "    print('ResNet:', resnet_mts[resnet_mts['dataset_name'] == data_name]['accuracy'].values[0] if len(resnet_mts[resnet_mts['dataset_name'] == data_name]['accuracy'].values) >= 1 else 'N/A')\n",
    "    print('HIVE-COTE:', hive_cote[hive_cote['dataset_name'] == data_name]['HIVE-COTE'].values[0] if len(hive_cote[hive_cote['dataset_name'] == data_name]['HIVE-COTE'].values) >= 1 else 'N/A')\n",
    "    print('DTW:', dtw_uea[dtw_uea['dataset_name'] == data_name]['DTW'].values[0] if len(dtw_uea[dtw_uea['dataset_name'] == data_name]['DTW'].values) == 1 else 'N/A')\n",
    "    print('*'*10)\n",
    "    \n",
    "#     results.append({'dataset': data_name, 'dim': codings_train.shape[1], \n",
    "# #                     'RF-ACC': rf_scores['accuracy'], \n",
    "#                     'SVM-ACC': svm_scores['accuracy'],\n",
    "# #                     '1NN-ACC': knn_scores['accuracy'], \n",
    "#                     # 'MLP-ACC': mlp_scores['accuracy'], \n",
    "# #                     'RF-F1': rf_scores['f1'], \n",
    "#                     'SVM-F1': svm_scores['f1'],\n",
    "# #                     '1NN-F1': knn_scores['f1'], \n",
    "#                     # 'MLP-F1': mlp_scores['f1'],\n",
    "#                     'duration (sec)': duration\n",
    "#                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mul_datasets = ['ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions', 'Cricket', 'EthanolConcentration',\n",
    "                         'ERing', 'HandMovementDirection', 'Handwriting', 'JapaneseVowels', 'PenDigits', 'RacketSports', 'SelfRegulationSCP1',\n",
    "                         'SelfRegulationSCP2', 'SpokenArabicDigits', 'StandWalkJump']\n",
    "\n",
    "selected_uni_datasets = ['ArrowHead', 'BeetleFly', 'ChlorineConcentration', 'Crop', 'DiatomSizeReduction', 'Earthquakes','ECG200', 'ECG5000', 'ECGFiveDays',\n",
    "                         'FreezerSmallTrain', 'Fungi', 'GunPoint', 'GunPointAgeSpan','GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Herring', \n",
    "                         'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'Lightning2', 'MedicalImages', 'MiddlePhalanxTW',\n",
    "                         'NonInvasiveFetalECGThorax2', 'OliveOil', 'PhalangesOutlinesCorrect', 'PickupGestureWiimoteZ','PigAirwayPressure', 'PowerCons',\n",
    "                         'ProximalPhalanxOutlineAgeGroup', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'SmoothSubspace', 'StarLightCurves',\n",
    "                         'SyntheticControl', 'Trace', 'UMD', 'UWaveGestureLibraryAll', 'Wafer', 'Yoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  GunPointOldVersusYoung\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 128 should be equal to 384, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d831c245b5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muni_datasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munivariate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'- END -'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3d1bd1f0016d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_name, univariate)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodings_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0msvm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM >>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/patara/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/patara/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/patara/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    472\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    473\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 128 should be equal to 384, the number of features at training time"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# print('-'*10)\n",
    "# print('Multivariate')\n",
    "# print('-'*10)\n",
    "# for dataset in selected_mul_datasets:\n",
    "#     evaluate(dataset, univariate=False)\n",
    "# print('='*10)\n",
    "\n",
    "# print('-'*10)\n",
    "# print('Univariate')\n",
    "# print('-'*10)\n",
    "\n",
    "uni_datasets = ['GunPointOldVersusYoung', 'SmoothSubspace', 'Earthquakes', 'InsectWingbeatSound', 'OliveOil', 'NonInvasiveFetalECGThorax2', 'InsectEPGRegularTrain', 'UWaveGestureLibraryAll', 'PigAirwayPressure', 'Fungi']\n",
    "\n",
    "for dataset in uni_datasets:\n",
    "    evaluate(dataset, univariate=True)\n",
    "\n",
    "print('- END -')\n",
    "\n",
    "# pd.DataFrame(results).to_csv('./results/final-results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
